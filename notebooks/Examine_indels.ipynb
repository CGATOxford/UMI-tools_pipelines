{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: During startup - \n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: Warning messages:\n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 1: package ‘methods’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 2: package ‘datasets’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 3: package ‘utils’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 4: package ‘grDevices’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 5: package ‘graphics’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 6: package ‘stats’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "import collections\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = \"/ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/Nxf1-GFP-R2.bam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains test code to examine whether indel mutations in UMIs present a substainal effect. To test this, we first recognise that a one base pair indel will suck a base of the actual genomic sequencing into the UMI, shifting the mapping position of the by one base, and including a genome determined base as the final base of the UMI.\n",
    "\n",
    "To test this we will parse the bam file and fill a dictionary: key=\"[contig][position]\", value= counter of UMIs for each position. Then we'll parse the dictionary keys and look to see whether the positions +1 exist in the dictionary keys. If they do, we'll compare the umi profiles between the postions. \n",
    "\n",
    "First we will filter for UMIs that have the genomic base in the final UMI position. Then we will check for each possible one bp deletion in the reference UMI and see if that UMI exists in the +1 position. We will calculate what % of the UMIs at the reference position exist as deletion versions at +1 and what % of reads at +1 are deletion versions releative to the reference base.\n",
    "\n",
    "This will then be compared to a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'GCGAT': 150, 'ATAGT': 100, 'AGTAG': 10})\n",
      "Counter({'GACAG': 1000, 'CCAGA': 20, 'ATGTA': 2})\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "umis1 = collections.Counter()\n",
    "umis2 = collections.Counter()\n",
    "umis1[\"ATAGT\"] = 100\n",
    "umis1[\"AGTAG\"] = 10\n",
    "umis1[\"GCGAT\"] = 150\n",
    "\n",
    "umis2[\"ATGTA\"] = 2\n",
    "umis2[\"GACAG\"] = 1000\n",
    "umis2[\"CCAGA\"] = 20\n",
    "\n",
    "print umis1\n",
    "print umis2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to calculate the fraction of the reference and plus 1 base UMIs that are part of deletion pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as_fraction_of_plus1': 0.3333333333333333,\n",
       " 'as_fraction_of_ref': 0.3333333333333333,\n",
       " 'weighted_fraction_of_plus1': 0.0019569471624266144,\n",
       " 'weighted_fraction_of_ref': 0.38461538461538464}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDelFraction(counter1, counter2, genomic_base):\n",
    "    ''' for two counters with string keys,\n",
    "    return the fraction of bases at counter2 that could be deletions cf conuter1'''\n",
    "    \n",
    "    umis1 = counter1.keys()\n",
    "    umis2 = counter2.keys()\n",
    "    \n",
    "    found1 = set()\n",
    "    found2 = set()\n",
    "    \n",
    "    filtered_set2 = set([umi[:-1] for umi in umis2 if umi[-1] == genomic_base])\n",
    "    for umi in umis1:\n",
    "        for i in range(len(umi)):\n",
    "            del_umi = umi[:i] + umi[i+1:]\n",
    "            if del_umi in filtered_set2:\n",
    "                found1.add(umi)\n",
    "                found2.add(del_umi+genomic_base)\n",
    "            \n",
    "    return {\"as_fraction_of_ref\": float(len(found1))/len(umis1),\n",
    "            \"as_fraction_of_plus1\": float(len(found2))/len(umis2),\n",
    "            \"weighted_fraction_of_ref\": float(sum([counter1[umi] for umi in found1]))/sum(counter1.values()),\n",
    "            \"weighted_fraction_of_plus1\": float(sum([counter2[umi] for umi in found2]))/sum(counter2.values())}\n",
    "getDelFraction(umis1, umis2, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now a function to parse a bam and create the dictionary.\n",
    "\n",
    "Because whether we care about +1 or -1 and whether we want to rev comp the sequence or not, we will deal with plus and minus strands seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_samfile(infile):\n",
    "    '''Parses a bamfile and returns three dictionaries, the first is a dictionary of counters\n",
    "    with the count of each umi at each bases on each contig, the second is the first bases matched\n",
    "    reads at that position, and the third is the distribution of the UMIs in the file'''\n",
    "    insam = pysam.Samfile(infile, \"rb\")\n",
    "\n",
    "    umi_pos = collections.defaultdict(lambda:collections.defaultdict(lambda: collections.Counter()))\n",
    "    umi_dist=collections.Counter()\n",
    "    genomic_bases = collections.defaultdict(lambda: collections.defaultdict(str))\n",
    "    inreads = insam.fetch()\n",
    "    for read in inreads:\n",
    "        if read.is_unmapped:\n",
    "            continue\n",
    "\n",
    "        if read.mate_is_unmapped and paired:\n",
    "            continue\n",
    "\n",
    "        if read.is_read2:\n",
    "            continue\n",
    "\n",
    "        is_spliced = False\n",
    "\n",
    "        if read.is_reverse:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            pos = read.pos\n",
    "            if read.cigar[0][0] == 4:\n",
    "                pos = pos - read.cigar[0][1]\n",
    "            start = pos\n",
    "\n",
    "            if ('N' in read.cigarstring or\n",
    "                (read.cigar[-1][0] == 4 and\n",
    "                 read.cigar[-1][1] > soft_clip_threshold)):\n",
    "                is_spliced = True\n",
    "\n",
    "        umi = read.qname.split(\"_\")[-1]\n",
    "        chrom = insam.get_reference_name(read.tid)\n",
    "        umi_pos[chrom][pos][umi] += 1\n",
    "        umi_dist[umi] += 1\n",
    "        \n",
    "        if read.cigar[0][0] == 0:\n",
    "            genomic_bases[chrom][pos] = read.query_sequence[0]\n",
    "                \n",
    "    return umi_pos, umi_dist, genomic_bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an undeduped sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undeduped_umi_pos, undeduped_umi_dist, undeduped_bases = parse_samfile(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "370674\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print len(undeduped_umi_pos)\n",
    "for k,v in undeduped_umi_pos.iteritems():\n",
    "    n += len(v)\n",
    "print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to go through each pair of adjecent positions and calculate the fraction of the UMIs at position +1 that could be explained as deletions of UMIs at the reference position. Then randomise the UMIs at the +1 position and do the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomise_position(umi_counter, umi_dist):\n",
    "    '''Takes a counter of UMI frequencies and create a randomised distribution by replacing the UMIs \n",
    "    in the input which UMIs sampled from the genomewide distribution'''\n",
    "    \n",
    "    return {umi: count for umi, count in \n",
    "            zip(np.random.choice(umi_dist[\"index\"], \n",
    "                                 size=len(umi_counter.keys()),\n",
    "                                 replace=False,\n",
    "                                 p=umi_dist[\"freq\"]),\n",
    "                                 umi_counter.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "undeduped_umi_dist = pd.Series(undeduped_umi_dist, name=\"count\").reset_index()\n",
    "undeduped_umi_dist[\"freq\"] = undeduped_umi_dist[\"count\"] / undeduped_umi_dist[\"count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_deletion_rate(umi_pos, umi_dist, genomic_bases):\n",
    "    '''Find positions where position+1 also has UMIs and calculate the deletion rate,\n",
    "    in comparision to randomised UMIs'''\n",
    "    skipped = 0\n",
    "    results_accumulator = []\n",
    "    random_accumulator = []\n",
    "    for contig in umi_pos:\n",
    "        for position in umi_pos[contig]:\n",
    "            if position+1 in umi_pos[contig]:\n",
    "                genomic_base = genomic_bases[contig][position]\n",
    "                if genomic_base == str():\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                this =  umi_pos[contig][position]\n",
    "                other = umi_pos[contig][position + 1]\n",
    "                \n",
    "\n",
    "                rand_other = randomise_position(other, umi_dist)\n",
    "                results_accumulator.append(getDelFraction(this, other, genomic_base))\n",
    "                random_accumulator.append(getDelFraction(this, rand_other, genomic_base))\n",
    "            \n",
    "    results_frame = pd.DataFrame(results_accumulator)\n",
    "    random_accumulator = pd.DataFrame(random_accumulator)\n",
    "\n",
    "    results_frame[\"random\"] = 0\n",
    "    random_accumulator[\"random\"] = 1\n",
    "\n",
    "    results_frame = pd.concat([results_frame, random_accumulator])\n",
    "    print skipped\n",
    "    return results_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "undeduped_deletion_rates = calculate_deletion_rate(undeduped_umi_pos, undeduped_umi_dist, undeduped_bases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having calculated the deledtion rates, lets look at the distribution, for both randomised and non-randomised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>as_fraction_of_plus1</th>\n",
       "      <th>as_fraction_of_ref</th>\n",
       "      <th>weighted_fraction_of_plus1</th>\n",
       "      <th>weighted_fraction_of_ref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0</th>\n",
       "      <th>count</th>\n",
       "      <td>35998.000000</td>\n",
       "      <td>35998.000000</td>\n",
       "      <td>35998.000000</td>\n",
       "      <td>35998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050737</td>\n",
       "      <td>0.072235</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.072904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.135960</td>\n",
       "      <td>0.187270</td>\n",
       "      <td>0.143054</td>\n",
       "      <td>0.192871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>35998.000000</td>\n",
       "      <td>35998.000000</td>\n",
       "      <td>35998.000000</td>\n",
       "      <td>35998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.039568</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>0.039544</td>\n",
       "      <td>0.066186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.100434</td>\n",
       "      <td>0.173073</td>\n",
       "      <td>0.107504</td>\n",
       "      <td>0.180149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              as_fraction_of_plus1  as_fraction_of_ref  \\\n",
       "random                                                   \n",
       "0      count          35998.000000        35998.000000   \n",
       "       mean               0.050737            0.072235   \n",
       "       std                0.135960            0.187270   \n",
       "       min                0.000000            0.000000   \n",
       "       25%                0.000000            0.000000   \n",
       "       50%                0.000000            0.000000   \n",
       "       75%                0.000000            0.000000   \n",
       "       max                1.000000            1.000000   \n",
       "1      count          35998.000000        35998.000000   \n",
       "       mean               0.039568            0.065143   \n",
       "       std                0.100434            0.173073   \n",
       "       min                0.000000            0.000000   \n",
       "       25%                0.000000            0.000000   \n",
       "       50%                0.000000            0.000000   \n",
       "       75%                0.000000            0.000000   \n",
       "       max                1.000000            1.000000   \n",
       "\n",
       "              weighted_fraction_of_plus1  weighted_fraction_of_ref  \n",
       "random                                                              \n",
       "0      count                35998.000000              35998.000000  \n",
       "       mean                     0.051454                  0.072904  \n",
       "       std                      0.143054                  0.192871  \n",
       "       min                      0.000000                  0.000000  \n",
       "       25%                      0.000000                  0.000000  \n",
       "       50%                      0.000000                  0.000000  \n",
       "       75%                      0.000000                  0.000000  \n",
       "       max                      1.000000                  1.000000  \n",
       "1      count                35998.000000              35998.000000  \n",
       "       mean                     0.039544                  0.066186  \n",
       "       std                      0.107504                  0.180149  \n",
       "       min                      0.000000                  0.000000  \n",
       "       25%                      0.000000                  0.000000  \n",
       "       50%                      0.000000                  0.000000  \n",
       "       75%                      0.000000                  0.000000  \n",
       "       max                      1.000000                  1.000000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undeduped_deletion_rates.groupby(\"random\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an enrichment compared to the randomisations. Small but clearly present. The overlap is zero in the vast majority of cases. The important measure is the UMIs as a fractin of the +1 position - these are UMIs that are not real. The means are different, but the overlap is zero in the vast majoirty of cases. How many cases are they non-zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_fraction_of_plus1</th>\n",
       "      <th>as_fraction_of_ref</th>\n",
       "      <th>weighted_fraction_of_plus1</th>\n",
       "      <th>weighted_fraction_of_ref</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8593</td>\n",
       "      <td>8593</td>\n",
       "      <td>8593</td>\n",
       "      <td>8593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8276</td>\n",
       "      <td>8276</td>\n",
       "      <td>8276</td>\n",
       "      <td>8276</td>\n",
       "      <td>35998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        as_fraction_of_plus1  as_fraction_of_ref  weighted_fraction_of_plus1  \\\n",
       "random                                                                         \n",
       "0                       8593                8593                        8593   \n",
       "1                       8276                8276                        8276   \n",
       "\n",
       "        weighted_fraction_of_ref  random  \n",
       "random                                    \n",
       "0                           8593       0  \n",
       "1                           8276   35998  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undeduped_deletion_rates.groupby(\"random\").apply(lambda x: (x>0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its a very small difference at this level. Some 300 positions or so. The real imporant descision is whether or not this enrichment is still present after deduplication. \n",
    "\n",
    "Compare to the deduped files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "deduped_umi_pos, deduped_umi_dist, deduped_bases = parse_samfile(\n",
    "    \"/ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/dedup_directional-adjacency.dir/Nxf1-GFP-R2.bam\")\n",
    "deduped_umi_dist = pd.Series(deduped_umi_dist, name=\"count\").reset_index()\n",
    "deduped_umi_dist[\"freq\"] = deduped_umi_dist[\"count\"] / deduped_umi_dist[\"count\"].sum()\n",
    "deduped_deletion_rates = calculate_deletion_rate(deduped_umi_pos, deduped_umi_dist, deduped_bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_fraction_of_plus1</th>\n",
       "      <th>as_fraction_of_ref</th>\n",
       "      <th>weighted_fraction_of_plus1</th>\n",
       "      <th>weighted_fraction_of_ref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045836</td>\n",
       "      <td>0.053993</td>\n",
       "      <td>0.045836</td>\n",
       "      <td>0.053993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035691</td>\n",
       "      <td>0.046084</td>\n",
       "      <td>0.035691</td>\n",
       "      <td>0.046084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        as_fraction_of_plus1  as_fraction_of_ref  weighted_fraction_of_plus1  \\\n",
       "random                                                                         \n",
       "0                   0.045836            0.053993                    0.045836   \n",
       "1                   0.035691            0.046084                    0.035691   \n",
       "\n",
       "        weighted_fraction_of_ref  \n",
       "random                            \n",
       "0                       0.053993  \n",
       "1                       0.046084  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_deletion_rates.groupby(\"random\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_fraction_of_plus1</th>\n",
       "      <th>as_fraction_of_ref</th>\n",
       "      <th>weighted_fraction_of_plus1</th>\n",
       "      <th>weighted_fraction_of_ref</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8147</td>\n",
       "      <td>8147</td>\n",
       "      <td>8147</td>\n",
       "      <td>8147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7708</td>\n",
       "      <td>7708</td>\n",
       "      <td>7708</td>\n",
       "      <td>7708</td>\n",
       "      <td>35998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        as_fraction_of_plus1  as_fraction_of_ref  weighted_fraction_of_plus1  \\\n",
       "random                                                                         \n",
       "0                       8147                8147                        8147   \n",
       "1                       7708                7708                        7708   \n",
       "\n",
       "        weighted_fraction_of_ref  random  \n",
       "random                                    \n",
       "0                           8147       0  \n",
       "1                           7708   35998  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_deletion_rates.groupby(\"random\").apply(lambda x: (x>0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The enrichment is smaller, but not by much. The biggest difference is that the there is a smaller number of overlapping positions in the randomised positions.\n",
    "\n",
    "How much are the enrichments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "as_fraction_of_plus1          1.282277\n",
       "as_fraction_of_ref            1.108869\n",
       "weighted_fraction_of_plus1    1.301189\n",
       "weighted_fraction_of_ref      1.101507\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undeduped_means = undeduped_deletion_rates.groupby(\"random\").mean()\n",
    "undeduped_means.loc[0]/undeduped_means.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "as_fraction_of_plus1          1.284248\n",
       "as_fraction_of_ref            1.171609\n",
       "weighted_fraction_of_plus1    1.284248\n",
       "weighted_fraction_of_ref      1.171609\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_means = deduped_deletion_rates.groupby(\"random\").mean()\n",
    "deduped_means.loc[0]/deduped_means.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these enrichments compared to the enrichments caused by edit_disatance enrichments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directional-adjacency</th>\n",
       "      <th>directional-adjacency_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>unique_null</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit_distance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Single_UMI</th>\n",
       "      <td>676164</td>\n",
       "      <td>676164</td>\n",
       "      <td>661329</td>\n",
       "      <td>661329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>388</td>\n",
       "      <td>14791</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3312</td>\n",
       "      <td>2311</td>\n",
       "      <td>3540</td>\n",
       "      <td>3511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7697</td>\n",
       "      <td>7980</td>\n",
       "      <td>8181</td>\n",
       "      <td>11627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43520</td>\n",
       "      <td>43954</td>\n",
       "      <td>43709</td>\n",
       "      <td>50401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8595</td>\n",
       "      <td>8597</td>\n",
       "      <td>7875</td>\n",
       "      <td>11928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               directional-adjacency  directional-adjacency_null  unique  \\\n",
       "edit_distance                                                              \n",
       "Single_UMI                    676164                      676164  661329   \n",
       "0                                  0                          31       0   \n",
       "1                                137                         388   14791   \n",
       "2                               3312                        2311    3540   \n",
       "3                               7697                        7980    8181   \n",
       "4                              43520                       43954   43709   \n",
       "5                               8595                        8597    7875   \n",
       "6                                  0                           0       0   \n",
       "\n",
       "               unique_null  \n",
       "edit_distance               \n",
       "Single_UMI          661329  \n",
       "0                       37  \n",
       "1                      592  \n",
       "2                     3511  \n",
       "3                    11627  \n",
       "4                    50401  \n",
       "5                    11928  \n",
       "6                        0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance = pd.read_csv(\n",
    "    \"/ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/dedup_directional-adjacency.dir/Nxf1-GFP-R2_edit_distance.tsv\", sep=\"\\t\")\n",
    "edit_distance = edit_distance.set_index(\"edit_distance\")\n",
    "edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edit_distance_fractions = edit_distance.drop(\"Single_UMI\", axis=0).apply(lambda x: x/sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edit_distance\n",
       "0     0.000000\n",
       "1    24.984797\n",
       "2     1.008260\n",
       "3     0.703621\n",
       "4     0.867225\n",
       "5     0.660211\n",
       "6          NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance_fractions[\"unique\"]/edit_distance_fractions[\"unique_null\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the substitution errors are a 25x enrichment, rather than a 1.3 fold enrichment for the deletions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
