{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: During startup - \n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: Warning messages:\n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 1: package ‘methods’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 2: package ‘datasets’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 3: package ‘utils’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 4: package ‘grDevices’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 5: package ‘graphics’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n",
      "/shared/conda-install/envs/cgat-devel-lite/lib/python2.7/site-packages/rpy2/robjects/robject.py:6: UserWarning: 6: package ‘stats’ was built under R version 3.2.4 \n",
      "\n",
      "  rpy2.rinterface.initr()\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "import collections\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = \"mapping.dir/Nxf1-GFP-R1.bam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains test code to examine whether indel mutations in UMIs present a substainal effect. To test this, we first recognise that a one base pair indel will suck a base of the actual genomic sequencing into the UMI, shifting the mapping position of the by one base, and including a genome determined base as the final base of the UMI.\n",
    "\n",
    "To test this we will parse the bam file and fill a dictionary: key=\"[contig][position]\", value= counter of UMIs for each position. Then we'll parse the dictionary keys and look to see whether the positions +1 exist in the dictionary keys. If they do, we'll compare the umi profiles between the postions. \n",
    "\n",
    "First we will filter for UMIs that have the genomic base in the final UMI position. Then we will check for each possible one bp deletion in the reference UMI and see if that UMI exists in the +1 position. We will count the number of UMIs in the + 1 position that match this criteria. This way we will count the number of UMIs that may have arisen from a deletion. \n",
    "\n",
    "This will then be compared to a random sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to calculate the number of the reference and plus 1 base UMIs that are part of deletion pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDelNumber(counter1, counter2, genomic_base):\n",
    "    \n",
    "    umis1 = counter1.keys()\n",
    "    umis2 = counter2.keys()\n",
    "    \n",
    "    found1 = set()\n",
    "    found2 = set()\n",
    "    \n",
    "    filtered_set2 = set([umi[:-1] for umi in umis2 if umi[-1] == genomic_base])\n",
    "    for umi in umis1:\n",
    "        for i in range(len(umi)):\n",
    "            del_umi = umi[:i] + umi[i+1:]\n",
    "            if del_umi in filtered_set2:\n",
    "                found1.add(umi)\n",
    "                found2.add(del_umi+genomic_base)\n",
    "            \n",
    "    return  len(found2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now a function to parse a bam and create a dictionary containing the count of each UMI at each position.\n",
    "\n",
    "Because whether we care about +1 or -1 and whether we want to rev comp the sequence or not, we will deal with plus and minus strands seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_samfile(infile):\n",
    "    '''Parses a bamfile and returns three dictionaries, the first is a dictionary of counters\n",
    "    with the count of each umi at each bases on each contig, the second is the first bases matched\n",
    "    reads at that position, and the third is the distribution of the UMIs in the file'''\n",
    "    insam = pysam.Samfile(infile, \"rb\")\n",
    "\n",
    "    umi_pos = collections.defaultdict(lambda:collections.defaultdict(lambda: collections.Counter()))\n",
    "    umi_dist=collections.Counter()\n",
    "    genomic_bases = collections.defaultdict(lambda: collections.defaultdict(str))\n",
    "    inreads = insam.fetch()\n",
    "    for read in inreads:\n",
    "        if read.is_unmapped:\n",
    "            continue\n",
    "\n",
    "        if read.mate_is_unmapped and paired:\n",
    "            continue\n",
    "\n",
    "        if read.is_read2:\n",
    "            continue\n",
    "\n",
    "        is_spliced = False\n",
    "\n",
    "        if read.is_reverse:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            pos = read.pos\n",
    "            if read.cigar[0][0] == 4:\n",
    "                pos = pos - read.cigar[0][1]\n",
    "            start = pos\n",
    "\n",
    "            if ('N' in read.cigarstring or\n",
    "                (read.cigar[-1][0] == 4 and\n",
    "                 read.cigar[-1][1] > soft_clip_threshold)):\n",
    "                is_spliced = True\n",
    "\n",
    "        umi = read.qname.split(\"_\")[-1]\n",
    "        chrom = insam.get_reference_name(read.tid)\n",
    "        umi_pos[chrom][pos][umi] += 1\n",
    "        umi_dist[umi] += 1\n",
    "        \n",
    "        if read.cigar[0][0] == 0:\n",
    "            genomic_bases[chrom][pos] = read.query_sequence[0]\n",
    "                \n",
    "    return umi_pos, umi_dist, genomic_bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a single sample as test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undeduped_umi_pos, undeduped_umi_dist, undeduped_bases = parse_samfile(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to go through each pair of adjecent positions and calculate the fraction of the UMIs at position +1 that could be explained as deletions of UMIs at the reference position. Then randomise the UMIs at the +1 position and do the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomise_position(umi_counter, umi_dist):\n",
    "    '''Takes a counter of UMI frequencies and create a randomised distribution by replacing the UMIs \n",
    "    in the input which UMIs sampled from the genomewide distribution'''\n",
    "    \n",
    "    return {umi: count for umi, count in \n",
    "            zip(np.random.choice(umi_dist[\"index\"], \n",
    "                                 size=len(umi_counter.keys()),\n",
    "                                 replace=False,\n",
    "                                 p=umi_dist[\"freq\"]),\n",
    "                                 umi_counter.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_deletion_rate(umi_pos, umi_dist, genomic_bases, sum_func=getDelNumber):\n",
    "    '''Find positions where position+1 also has UMIs and calculate the deletion rate,\n",
    "    in comparision to randomised UMIs'''\n",
    "\n",
    "    # convert count umi_dist list to dataframe mapping umi to frequencies\n",
    "    umi_dist = pd.Series(umi_dist, name=\"count\").reset_index()\n",
    "    umi_dist[\"freq\"] = umi_dist[\"count\"]/umi_dist[\"count\"].sum()\n",
    "    \n",
    "    results_accumulator = []\n",
    "    random_accumulator = []\n",
    "    for contig in umi_pos:\n",
    "        for position in umi_pos[contig]:\n",
    "\n",
    "            genomic_base = genomic_bases[contig][position]\n",
    "            if genomic_base == str():\n",
    "                continue\n",
    "            this =  umi_pos[contig][position]\n",
    "            if position +1 in umi_pos[contig]:\n",
    "                other = umi_pos[contig][position + 1]\n",
    "            else:\n",
    "                other = collections.Counter()\n",
    "                \n",
    "            rand_other = randomise_position(other, umi_dist)\n",
    "            results_accumulator.append(sum_func(this, other, genomic_base))\n",
    "            random_accumulator.append(sum_func(this, rand_other, genomic_base))\n",
    "\n",
    "    results_frame = pd.DataFrame({\"deletion_rate\": results_accumulator})\n",
    "    random_accumulator = pd.DataFrame({\"deletion_rate\": random_accumulator})\n",
    "\n",
    "    results_frame[\"random\"] = False\n",
    "    random_accumulator[\"random\"] = True\n",
    "\n",
    "    results_frame = pd.concat([results_frame, random_accumulator])\n",
    "    return results_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run this on our selected test case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "undedup_deletion_numbers = calculate_deletion_rate(undeduped_umi_pos, undeduped_umi_dist, undeduped_bases, getDelNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want to look at is not the number of UMIs that might result from Indels, but the fractions, so we need to divide by the total number of UMIs seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deletion_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.113264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.105064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        deletion_rate\n",
       "random               \n",
       "False        0.113264\n",
       "True         0.105064"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undedup_deletion_numbers.groupby(\"random\").sum()/sum([len(undeduped_umi_pos[contig][base].keys()) for contig in undeduped_umi_pos for base in undeduped_umi_pos[contig]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things to note is that 10% is quite a lot. Second is that it is around 10% in both the actaul data and in the randomised control. This is not so unexpected because there are 5 possible deletion matches for each UMI, and if there are multiple UMIs at each of the adjecent positions, then it there is quite a high chance one will match. Particularly is you consider that many of the UMIs will occur in positions with many UMIs at them. These are more likely to have adjecent positions with reads mapping, and those positions are also likely to have many UMIs mapping. \n",
    "\n",
    "The total enrichment is lower 11.3%/10% ~ 1.08 fold enrichement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now  to run on all of the files in repilcate 1 of the experiment. Frist find the deduplicated files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SRSF5-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "SRSF7-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "Control-GFP-R1.bam    /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "SRSF3-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "SRSF6-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "SRSF4-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "Nxf1-GFP-R1.bam       /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "SRSF1-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "SRSF2-GFP-R1.bam      /ifs/projects/ians/umisdeduping/iCLIP_deduping...\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "infiles = pd.Series(glob.glob(\"mapping.dir/*R1.bam\"))\n",
    "infiles.index = infiles.apply(os.path.basename)\n",
    "infiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a wrapper function that encloses the whole analysis in one function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_number_analysis(infile):\n",
    "    print \"analysing \", infile\n",
    "    umi_pos, umi_dist, bases = parse_samfile(infile)\n",
    "    deletion_rates = calculate_deletion_rate(umi_pos, umi_dist, bases, getDelNumber)\n",
    "    total = sum([len(umi_pos[contig][base].keys()) for contig in umi_pos for base in umi_pos[contig]])\n",
    "    return (deletion_rates.groupby(\"random\").sum()/total)[\"deletion_rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and apply this accross all the input files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF5-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF7-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/Control-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF3-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF6-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF4-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/Nxf1-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF1-GFP-R1.bam\n",
      "analysing  /ifs/projects/ians/umisdeduping/iCLIP_deduping/SR_iCLIP_test3/mapping.dir/SRSF2-GFP-R1.bam\n"
     ]
    }
   ],
   "source": [
    "results = infiles.apply(run_number_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulate the enrichment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>random</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>enrichment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRSF5-GFP-R1.bam</th>\n",
       "      <td>0.085877</td>\n",
       "      <td>0.084387</td>\n",
       "      <td>1.017658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRSF7-GFP-R1.bam</th>\n",
       "      <td>0.039137</td>\n",
       "      <td>0.036899</td>\n",
       "      <td>1.060653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control-GFP-R1.bam</th>\n",
       "      <td>0.022180</td>\n",
       "      <td>0.016067</td>\n",
       "      <td>1.380488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRSF3-GFP-R1.bam</th>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>1.123770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRSF6-GFP-R1.bam</th>\n",
       "      <td>0.056353</td>\n",
       "      <td>0.053947</td>\n",
       "      <td>1.044607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRSF4-GFP-R1.bam</th>\n",
       "      <td>0.101630</td>\n",
       "      <td>0.094871</td>\n",
       "      <td>1.071246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nxf1-GFP-R1.bam</th>\n",
       "      <td>0.113264</td>\n",
       "      <td>0.104850</td>\n",
       "      <td>1.080242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRSF1-GFP-R1.bam</th>\n",
       "      <td>0.072417</td>\n",
       "      <td>0.064592</td>\n",
       "      <td>1.121152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRSF2-GFP-R1.bam</th>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>1.025946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "random                 False      True  enrichment\n",
       "SRSF5-GFP-R1.bam    0.085877  0.084387    1.017658\n",
       "SRSF7-GFP-R1.bam    0.039137  0.036899    1.060653\n",
       "Control-GFP-R1.bam  0.022180  0.016067    1.380488\n",
       "SRSF3-GFP-R1.bam    0.048327  0.043004    1.123770\n",
       "SRSF6-GFP-R1.bam    0.056353  0.053947    1.044607\n",
       "SRSF4-GFP-R1.bam    0.101630  0.094871    1.071246\n",
       "Nxf1-GFP-R1.bam     0.113264  0.104850    1.080242\n",
       "SRSF1-GFP-R1.bam    0.072417  0.064592    1.121152\n",
       "SRSF2-GFP-R1.bam    0.064955  0.063312    1.025946"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"enrichment\"] = results[False]/results[True]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>enrichment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.803755</td>\n",
       "      <td>-2.897659</td>\n",
       "      <td>0.093904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.509219</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.092416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.808545</td>\n",
       "      <td>-4.130982</td>\n",
       "      <td>0.017504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.029771</td>\n",
       "      <td>-3.146459</td>\n",
       "      <td>0.043641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.734061</td>\n",
       "      <td>-2.759676</td>\n",
       "      <td>0.068822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.454841</td>\n",
       "      <td>-2.472345</td>\n",
       "      <td>0.114357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-2.178036</td>\n",
       "      <td>-2.255221</td>\n",
       "      <td>0.322437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          False      True  enrichment\n",
       "count  9.000000  9.000000    9.000000\n",
       "mean  -2.803755 -2.897659    0.093904\n",
       "std    0.509219  0.578451    0.092416\n",
       "min   -3.808545 -4.130982    0.017504\n",
       "25%   -3.029771 -3.146459    0.043641\n",
       "50%   -2.734061 -2.759676    0.068822\n",
       "75%   -2.454841 -2.472345    0.114357\n",
       "max   -2.178036 -2.255221    0.322437"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.apply(np.log).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the mean enrichment is 1.1x (+/- standard deviation of 0.1) over random. Pretty low. It could be argued that even if its low we could ebefit from removing it. Applying the same rules as directional, we will see how many are within the 2n+1 threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getThresholdedNumber(counter1, counter2, genomic_base):\n",
    "\n",
    "    umis1 = counter1.keys()\n",
    "    umis2 = counter2.keys()\n",
    "    \n",
    "    found1 = set()\n",
    "    found2 = set()\n",
    "    \n",
    "    filtered_set2 = set([umi[:-1] for umi in umis2 if umi[-1] == genomic_base])\n",
    "    for umi in umis1:\n",
    "        for i in range(len(umi)):\n",
    "            del_umi = umi[:i] + umi[i+1:]\n",
    "            if del_umi in filtered_set2 and counter1[umi] > 2*counter2[del_umi+genomic_base] + 1:\n",
    "                found1.add(umi)\n",
    "                found2.add(del_umi+genomic_base)\n",
    "            \n",
    "    return  len(found2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undedup_threshold_numbers = calculate_deletion_rate(undeduped_umi_pos, undeduped_umi_dist, undeduped_bases, getThresholdedNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deletion_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.041546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.040011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        deletion_rate\n",
       "random               \n",
       "False        0.041546\n",
       "True         0.040011"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undedup_threshold_numbers.groupby(\"random\").sum()/sum([len(undeduped_umi_pos[contig][base].keys()) for contig in undeduped_umi_pos for base in undeduped_umi_pos[contig]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So of those 11% we found earlier that could be indel related purely on the basis of sequence, 4% also fulfill the count threshold. However, just as many of the random ones do as well. So if we were to remove these, of the 4.2% we would remove 4% would be erroneously removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these enrichments compared to the enrichments caused by edit_disatance enrichments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directional-adjacency</th>\n",
       "      <th>directional-adjacency_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>unique_null</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit_distance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Single_UMI</th>\n",
       "      <td>1258729</td>\n",
       "      <td>1258729</td>\n",
       "      <td>1241294</td>\n",
       "      <td>1241294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219</td>\n",
       "      <td>654</td>\n",
       "      <td>17526</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5716</td>\n",
       "      <td>3950</td>\n",
       "      <td>5922</td>\n",
       "      <td>5534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13516</td>\n",
       "      <td>13840</td>\n",
       "      <td>14210</td>\n",
       "      <td>18111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67613</td>\n",
       "      <td>68440</td>\n",
       "      <td>67835</td>\n",
       "      <td>76169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14082</td>\n",
       "      <td>14208</td>\n",
       "      <td>13088</td>\n",
       "      <td>17780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               directional-adjacency  directional-adjacency_null   unique  \\\n",
       "edit_distance                                                               \n",
       "Single_UMI                   1258729                     1258729  1241294   \n",
       "0                                  0                          54        0   \n",
       "1                                219                         654    17526   \n",
       "2                               5716                        3950     5922   \n",
       "3                              13516                       13840    14210   \n",
       "4                              67613                       68440    67835   \n",
       "5                              14082                       14208    13088   \n",
       "6                                  0                           0        0   \n",
       "\n",
       "               unique_null  \n",
       "edit_distance               \n",
       "Single_UMI         1241294  \n",
       "0                       63  \n",
       "1                      924  \n",
       "2                     5534  \n",
       "3                    18111  \n",
       "4                    76169  \n",
       "5                    17780  \n",
       "6                        0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance = pd.read_csv(\n",
    "    \"dedup_directional.dir/Nxf1-GFP-R1_edit_distance.tsv\", sep=\"\\t\")\n",
    "edit_distance = edit_distance.set_index(\"edit_distance\")\n",
    "edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edit_distance_fractions = edit_distance.drop(\"Single_UMI\", axis=0).apply(lambda x: x/sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edit_distance\n",
       "0     0.000000\n",
       "1    24.984797\n",
       "2     1.008260\n",
       "3     0.703621\n",
       "4     0.867225\n",
       "5     0.660211\n",
       "6          NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance_fractions[\"unique\"]/edit_distance_fractions[\"unique_null\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the substitution errors are a 25x enrichment, rather than a 1.1 fold enrichment for the deletions. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
